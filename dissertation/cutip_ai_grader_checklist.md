# CUTIP AI Grader Compatibility Checklist (Chapters 1–3)

**Purpose:**  
Pre-submission compatibility check against the CUTIP AI grading system  
(reverse-engineered from multiple graded dissertation proposals).

**Scope:**  
Chapters 1–3 only  
**Layer:** Presentation-layer validation (no theory mutation)

---

## A. HARD FAIL CONDITIONS  
**Any ❌ = rejection or “Major Revisions Required”**

### A1. Research Question ↔ Sample Isomorphism
- [ ] Every Research Question (RQ) is answerable **directly** by the sampled population  
- [ ] No RQ relies on proxy, hearsay, or inferred actors  
- [ ] No “user perception” RQ without user sampling  

---

### A2. Ontological Category Consistency
- [ ] CI, DNI, and SFEU are never blurred  
- [ ] Execution ≠ governance ≠ interpretation  
- [ ] No artifact crosses incompatible ontological categories  

---

### A3. Scope ↔ Method Capacity Match
- [ ] Methodology fully supports declared scope  
- [ ] No multi-regulatory-domain span without full stratification  
- [ ] Depth prioritized over breadth  

---

### A4. Internal Conceptual Coherence
- [ ] No internal contradictions across chapters  
- [ ] Definitions remain stable  
- [ ] Diagrams encode exactly what prose claims  

---

### A5. Method Minimalism
- [ ] No decorative or low-power methods  
- [ ] Every method has epistemic weight  
- [ ] No weak quantitative add-ons to qualitative cores  

---

## B. SCORE-CAPPING CONDITIONS  
**Violations cap scores at ~7–8**

### B1. Explicit Resolution of Theoretical Tensions
- [ ] Multiple theories are hierarchized or bounded  
- [ ] No unresolved theoretical conflicts  
- [ ] Dominance rules are explicit  

---

### B2. Metric / Claim Completeness
- [ ] No lossy single-scalar metrics  
- [ ] All institutional effects expose full observables  
- [ ] Equilibria are not reduced to proxies  

---

### B3. Threshold & Boundary Explicitness
- [ ] Success vs failure conditions defined  
- [ ] Falsification triggers explicit  
- [ ] No monotonic “more is better” claims  

---

### B4. Cultural / Institutional Legibility
- [ ] All authorities are legible in Thai context  
- [ ] Imported legitimacy is justified  
- [ ] Thailand used as destructive validator, not example  

---

### B5. Feasibility Closure
- [ ] All critical dependencies closed  
- [ ] No “awaiting confirmation” steps  
- [ ] Fallback paths defined  

---

## C. ETHICS COMPATIBILITY  
**Silent failure risk if mishandled**

### C1. Ethics as Architecture
- [ ] Ethics implemented as system constraints  
- [ ] No reliance on researcher intent  

---

### C2. Disclosure Timing Logic
- [ ] No premature disclosure contaminating data  
- [ ] No delayed disclosure violating autonomy  
- [ ] Withdrawal rights coherent  

---

### C3. Secondary Harm Coverage
- [ ] Reputational harm addressed  
- [ ] Institutional harm addressed  
- [ ] Governance misuse risk acknowledged  

---

## D. PRESENTATION-LAYER TRIGGERS  
**Low effort, high impact**

### D1. Diagram Hygiene
- [ ] Diagrams reflect dynamic claims  
- [ ] No linear diagrams for equilibrium systems  

---

### D2. Boundary Sentences
- [ ] Each chapter states what it does *not* do  
- [ ] No implicit policy advocacy in Ch. 1–2  

---

### D3. Terminology Stability
- [ ] Same term → same meaning everywhere  
- [ ] No synonym drift  

---

## E. Predicted CUTIP AI Outcome

**PASS (High Distinction Compatible)**  
Risk class: Low  
Failure basin: Avoided  

---

## Governing Principle

> *The dissertation is evaluated as a system, not a story.*  
> Coherence > novelty  
> Execution logic > ambition  
> Boundaries > breadth
